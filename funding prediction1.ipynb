import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, median_absolute_error
import xgboost as xgb
import chardet
import re
import warnings
warnings.filterwarnings('ignore')

# Function to clean funding amounts
def clean_funding_amount(amount):
    if pd.isna(amount):
        return np.nan
    if isinstance(amount, (int, float)):
        return amount

    amount_str = str(amount).strip()
    if re.match(r'^\d{1,2},\d{2},\d{3}$', amount_str):
        parts = amount_str.split(',')
        if len(parts) == 3:
            lakhs = int(parts[0])
            thousands = int(parts[1])
            remainder = int(parts[2])
            return (lakhs * 100000) + (thousands * 1000) + remainder

    clean_str = amount_str.replace(',', '')
    try:
        return float(clean_str)
    except (ValueError, TypeError):
        return np.nan

# Function to identify outliers
def identify_outliers(data, column, threshold=3):
    mean = data[column].mean()
    std = data[column].std()
    z_scores = (data[column] - mean) / std
    return data[abs(z_scores) > threshold].index

# Load dataset with encoding detection
filename = "D1.csv"
with open(filename, 'rb') as f:
    result = chardet.detect(f.read())
    encoding_used = result['encoding']

try:
    df = pd.read_csv(filename, encoding=encoding_used)
except UnicodeDecodeError:
    for encoding in ['utf-8', 'latin1', 'windows-1252', 'utf-16']:
        try:
            df = pd.read_csv(filename, encoding=encoding)
            encoding_used = encoding
            break
        except UnicodeDecodeError:
            continue
    else:
        raise Exception("All encoding attempts failed.")

# Standardize column names
df.columns = df.columns.str.strip().str.lower()

# Map common column names
column_mapping = {
    "funding_total_usd": "funding_total_usd",
    "total_funding": "funding_total_usd",
    "funding_amount": "funding_total_usd",
    "founded_at": "founded_at",
    "market": "market",
    "country_code": "country_code",
    "funding_rounds": "funding_rounds",
    "category_list": "category_list",
    "state_code": "state_code",
    "city": "city",
    "first_funding_at": "first_funding_at",
    "last_funding_at": "last_funding_at"
}

for old_name, new_name in column_mapping.items():
    if old_name in df.columns:
        df.rename(columns={old_name: new_name}, inplace=True)

# Convert funding to numeric
df["funding_total_usd"] = df["funding_total_usd"].apply(clean_funding_amount)
df["funding_rounds"] = pd.to_numeric(df["funding_rounds"], errors='coerce')

# Time-based features
df["founded_at"] = pd.to_datetime(df["founded_at"], errors='coerce')
df["first_funding_at"] = pd.to_datetime(df["first_funding_at"], errors='coerce')
df["last_funding_at"] = pd.to_datetime(df["last_funding_at"], errors='coerce')

df["years_since_founded"] = (pd.to_datetime("today") - df["founded_at"]).dt.days / 365.25
df["time_to_first_funding"] = (df["first_funding_at"] - df["founded_at"]).dt.days / 365.25
df["funding_duration"] = (df["last_funding_at"] - df["first_funding_at"]).dt.days / 365.25

# Advanced features
df["funding_velocity"] = df["funding_rounds"] / df["funding_duration"].replace(0, 0.1)
df["avg_funding_per_round"] = df["funding_total_usd"] / df["funding_rounds"].replace(0, 1)
df["funding_per_year"] = df["funding_total_usd"] / df["years_since_founded"].replace(0, 0.1)
df["quick_funding"] = (df["time_to_first_funding"] < 1).astype(int)

# Location features
if "state_code" in df.columns:
    df["has_state"] = df["state_code"].notna() & (df["state_code"] != "")
else:
    df["has_state"] = False

if "country_code" in df.columns:
    country_counts = df["country_code"].value_counts()
    common_countries = country_counts[country_counts >= 100].index
    df["country_group"] = df["country_code"].apply(lambda x: x if x in common_countries else "OTHER")

# Market features
if "market" in df.columns:
    df["market_main"] = df["market"].fillna("").astype(str).apply(lambda x: x.split()[0] if len(x.split()) > 0 else "Unknown")
    tech_markets = ['Software', 'Mobile', 'Internet', 'Enterprise', 'Web', 'Cloud', 'SaaS', 'AI', 'Machine']
    health_markets = ['Health', 'Medical', 'Healthcare', 'Biotech', 'Pharma']
    finance_markets = ['Finance', 'FinTech', 'Insurance', 'Banking', 'Investment']

    def categorize_market(market):
        if market in tech_markets:
            return 'Tech'
        elif market in health_markets:
            return 'Health'
        elif market in finance_markets:
            return 'Finance'
        else:
            return 'Other'

    df['market_sector'] = df['market_main'].apply(categorize_market)

# Handle infinities and NaNs
df.replace([np.inf, -np.inf], np.nan, inplace=True)
df["funding_rounds"] = df["funding_rounds"].fillna(0)
df["years FS"] = df["years_since_founded"].fillna(df["years_since_founded"].median())
df["time_to_first_funding"] = df["time_to_first_funding"].fillna(0)
df["funding_duration"] = df["funding_duration"].fillna(0)
df["funding_velocity"] = df["funding_velocity"].fillna(0)
df["avg_funding_per_round"] = df["avg_funding_per_round"].fillna(0)
df["funding_per_year"] = df["funding_per_year"].fillna(0)

# Filter valid funding data and remove outliers
df_filtered = df[df["funding_total_usd"] > 0].copy()
outlier_idx = identify_outliers(df_filtered, "funding_total_usd", threshold=4)
df_cleaned = df_filtered.drop(outlier_idx)

# Define features
features = [
    "country_group", "market_sector", "funding_rounds", "years_since_founded",
    "time_to_first_funding", "funding_duration", "funding_velocity",
    "avg_funding_per_round", "funding_per_year", "quick_funding", "has_state"
]

for feature in features:
    if feature not in df_cleaned.columns:
        df_cleaned[feature] = 0

# Prepare data
X = df_cleaned[features].copy()
y = np.log1p(df_cleaned["funding_total_usd"])  # Log transform target

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Encode categorical features
categorical_features = ["country_group", "market_sector"]
encoders = {}
for col in categorical_features:
    if col in X.columns:
        encoders[col] = LabelEncoder()
        X_train[col] = encoders[col].fit_transform(X_train[col].astype(str))
        X_test[col] = encoders[col].transform(X_test[col].astype(str))

# Scale numeric features
scaler = StandardScaler()
numeric_features = [col for col in X.columns if col not in categorical_features]
X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])
X_test[numeric_features] = scaler.transform(X_test[numeric_features])

# Train XGBoost model
xgb_model = xgb.XGBRegressor(
    n_estimators=300,
    learning_rate=0.1,  # Increased from 0.05
    max_depth=6,
    min_child_weight=1,
    subsample=0.8,
    colsample_bytree=0.8,
    gamma=0,
    reg_alpha=0.1,
    reg_lambda=1,
    random_state=42
)
xgb_model.fit(X_train, y_train)

# Evaluate model
y_pred = xgb_model.predict(X_test)
y_pred_exp = np.expm1(y_pred)
y_test_exp = np.expm1(y_test)
print(f"RÂ² Score: {r2_score(y_test_exp, y_pred_exp):.3f}")
print(f"MAE: ${mean_absolute_error(y_test_exp, y_pred_exp):,.2f}")
print(f"Median AE: ${median_absolute_error(y_test_exp, y_pred_exp):,.2f}")

# Prediction function
def predict_funding(new_data):
    new_data = new_data.copy()
    for feature in features:
        if feature not in new_data.columns:
            if feature in categorical_features:
                new_data[feature] = encoders[feature].classes_[0]
            else:
                new_data[feature] = 0

    for col, encoder in encoders.items():
        if col in new_data.columns:
            new_data[col] = new_data[col].astype(str)
            for i, val in enumerate(new_data[col]):
                if val not in encoder.classes_:
                    new_data.loc[i, col] = encoder.classes_[0]
            new_data[col] = encoder.transform(new_data[col])

    if numeric_features:
        new_data[numeric_features] = scaler.transform(new_data[numeric_features])

    prediction_input = new_data[features]
    log_pred = xgb_model.predict(prediction_input)
    print(f"Log prediction: {log_pred[0]}")  # Debug output
    return np.expm1(log_pred)

# Single startup prediction
def predict_single_startup(country_group, market_sector, funding_rounds,
                         years_since_founded, time_to_first_funding,
                         funding_duration, funding_velocity=None,
                         avg_funding_per_round=None, funding_per_year=None,
                         quick_funding=None, has_state=True):
    if funding_velocity is None:
        funding_velocity = funding_rounds / max(funding_duration, 0.1)
    if quick_funding is None:
        quick_funding = 1 if time_to_first_funding < 1 else 0
    if avg_funding_per_round is None:
        avg_funding_per_round = 1000000  # Default $1M per round
    if funding_per_year is None:
        funding_per_year = (avg_funding_per_round * funding_rounds) / max(years_since_founded, 0.1)

    test_data = pd.DataFrame({
        "country_group": [country_group],
        "market_sector": [market_sector],
        "funding_rounds": [funding_rounds],
        "years_since_founded": [years_since_founded],
        "time_to_first_funding": [time_to_first_funding],
        "funding_duration": [funding_duration],
        "funding_velocity": [funding_velocity],
        "avg_funding_per_round": [avg_funding_per_round],
        "funding_per_year": [funding_per_year],
        "quick_funding": [quick_funding],
        "has_state": [has_state]
    })

    prediction = predict_funding(test_data)
    return prediction[0]

# Example usage
if __name__ == "__main__":
    # Inspect training data
    print("Training data funding stats:")
    print(df_cleaned["funding_total_usd"].describe())

    # Test case
    prediction = predict_single_startup(
        "USA", "Tech", 3, 5, 0.5, 2.5
    )
    print(f"Predicted funding: ${prediction:,.2f}")
